"""Job search and filtering engine."""

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import structlog
from typing import List, Dict, Any, Optional
import urllib.parse

from .base_crawler import StealthCrawler
from .models import SearchFilters, JobType, ExperienceLevel

logger = structlog.get_logger()


class SearchEngine:
    """Handles job search and filtering operations."""
    
    def __init__(self, crawler: StealthCrawler):
        self.crawler = crawler
        self.site_config = crawler.site_config
        
    def navigate_to_jobs_page(self) -> None:
        """Navigate to the jobs search page."""
        import time
        start_time = time.time()
        
        try:
            jobs_url = self.site_config["jobs_url"]
            print(f"ðŸ”— ì±„ìš©ê³µê³  ê²€ìƒ‰ íŽ˜ì´ì§€ë¡œ ì´ë™ ì¤‘: {jobs_url}")
            logger.info(f"Navigating to jobs page: {jobs_url}")
            
            nav_start = time.time()
            self.crawler.driver.get(jobs_url)
            print("âœ… íŽ˜ì´ì§€ ì´ë™ ì™„ë£Œ!")
            logger.info(f"Jobs page navigation completed in {time.time() - nav_start:.2f}s")
            
            # Wait for page to load (reduced from 2-4s)
            print("â³ íŽ˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
            load_start = time.time()
            self.crawler.human_behavior.random_delay(1.0, 2.0)
            logger.info(f"Jobs page load wait completed in {time.time() - load_start:.2f}s")
            
            # Remove problematic mouse movements that cause "out of bounds" errors
            # self.crawler.human_behavior.random_mouse_movements(2)  # DISABLED
            
            # Simulate reading page content
            print("ðŸ‘€ íŽ˜ì´ì§€ ë‚´ìš© ì½ê¸° ì‹œë®¬ë ˆì´ì…˜ ì¤‘...")
            read_start = time.time()
            self.crawler.human_behavior.reading_pause(100)  # Reduced from 500
            print("âœ… íŽ˜ì´ì§€ ì¤€ë¹„ ì™„ë£Œ!")
            logger.info(f"Page reading simulation completed in {time.time() - read_start:.2f}s")
            
            logger.info(f"Successfully navigated to jobs page in {time.time() - start_time:.2f}s")
            
        except Exception as e:
            print(f"âŒ ì±„ìš©ê³µê³  íŽ˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}")
            logger.error(f"Failed to navigate to jobs page after {time.time() - start_time:.2f}s: {e}")
            raise
    
    def apply_search_filters(self, filters: SearchFilters) -> None:
        """Apply search filters based on the search criteria."""
        import time
        start_time = time.time()
        
        try:
            print("ðŸŽ¯ ê²€ìƒ‰ í•„í„° ì ìš©ì„ ì‹œìž‘í•©ë‹ˆë‹¤...")
            logger.info("Applying search filters")
            
            # Use Work24-specific filter flow
            if self.crawler.site_name == "work24":
                print("ðŸ¢ Work24 ì „ìš© í•„í„° ì ìš© ì¤‘...")
                self._apply_work24_filters(filters)
                print("âœ… Work24 í•„í„° ì ìš© ì™„ë£Œ!")
                logger.info(f"Work24 filters applied in {time.time() - start_time:.2f}s")
                return
            
            # Standard filter flow for other sites
            print("ðŸ“ í‘œì¤€ í•„í„° ì ìš© í”„ë¡œì„¸ìŠ¤ ì‹œìž‘...")
            
            # Apply keyword search
            if filters.keywords:
                print(f"ðŸ”¤ í‚¤ì›Œë“œ í•„í„° ì ìš© ì¤‘: '{filters.keywords}'")
                self._apply_keyword_filter(filters.keywords)
                print("âœ… í‚¤ì›Œë“œ í•„í„° ì ìš© ì™„ë£Œ!")
            
            # Apply location filter
            if filters.location:
                print(f"ðŸ“ ìœ„ì¹˜ í•„í„° ì ìš© ì¤‘: '{filters.location}'")
                self._apply_location_filter(filters.location)
                print("âœ… ìœ„ì¹˜ í•„í„° ì ìš© ì™„ë£Œ!")
            
            # Apply job type filter
            if filters.job_type:
                print(f"ðŸ’¼ ê³ ìš© í˜•íƒœ í•„í„° ì ìš© ì¤‘: {filters.job_type.value}")
                self._apply_job_type_filter(filters.job_type)
                print("âœ… ê³ ìš© í˜•íƒœ í•„í„° ì ìš© ì™„ë£Œ!")
            
            # Apply experience level filter
            if filters.experience_level:
                print(f"ðŸŽ“ ê²½ë ¥ ìˆ˜ì¤€ í•„í„° ì ìš© ì¤‘: {filters.experience_level.value}")
                self._apply_experience_filter(filters.experience_level)
                print("âœ… ê²½ë ¥ ìˆ˜ì¤€ í•„í„° ì ìš© ì™„ë£Œ!")
            
            # Apply date posted filter
            if filters.date_posted:
                print(f"ðŸ“… ê²Œì‹œì¼ í•„í„° ì ìš© ì¤‘: {filters.date_posted}")
                self._apply_date_filter(filters.date_posted)
                print("âœ… ê²Œì‹œì¼ í•„í„° ì ìš© ì™„ë£Œ!")
            
            # Apply remote work filter
            if filters.remote_only:
                print("ðŸ  ì›ê²©ê·¼ë¬´ í•„í„° ì ìš© ì¤‘...")
                self._apply_remote_filter()
                print("âœ… ì›ê²©ê·¼ë¬´ í•„í„° ì ìš© ì™„ë£Œ!")
            
            # Submit search
            print("ðŸš€ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
            self._submit_search()
            print("âœ… ê²€ìƒ‰ í•„í„° ì ìš© ë° ì‹¤í–‰ ì™„ë£Œ!")
            
            logger.info(f"Search filters applied successfully in {time.time() - start_time:.2f}s")
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ í•„í„° ì ìš© ì‹¤íŒ¨: {e}")
            logger.error(f"Failed to apply search filters after {time.time() - start_time:.2f}s: {e}")
            raise

    def _apply_work24_filters(self, filters: SearchFilters) -> None:
        """Apply Work24-specific search filters with proper section expansion."""
        import time
        
        try:
            logger.info("Applying Work24-specific search filters")
            print("ðŸ¢ Work24 í†µí•© ê²€ìƒ‰ í•„í„° ì ìš© ì‹œìž‘...")
            start_time = time.time()
            
            # 1. Enter keyword in search field (optional)
            if filters.keywords:
                print(f"ðŸ”¤ ê²€ìƒ‰ì–´ ìž…ë ¥ ì¤‘: '{filters.keywords}'")
                keyword_field = self.crawler.wait_for_element("#srcKeyword", timeout=10)
                if keyword_field:
                    keyword_field.clear()
                    self.crawler.human_behavior.human_type(keyword_field, filters.keywords)
                    print("âœ… ê²€ìƒ‰ì–´ ìž…ë ¥ ì™„ë£Œ!")
                    logger.info(f"Entered keywords: {filters.keywords}")
                else:
                    print("âŒ ê²€ìƒ‰ì–´ ìž…ë ¥ í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    logger.warning("Could not find keyword input field")
            else:
                print("â„¹ï¸ í‚¤ì›Œë“œ ì—†ì´ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # 2. Click "ì§ì¢…ì„ íƒ" button to expand job categories
            print("ðŸ“‚ ì§ì¢…ì„ íƒ ë²„íŠ¼ í´ë¦­í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ í™•ìž¥ ì¤‘...")
            try:
                category_button = self.crawler.wait_for_element(
                    self.site_config["selectors"]["filters"]["category_button"], timeout=10
                )
                if category_button:
                    self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", category_button)
                    self.crawler.human_behavior.random_delay(0.8, 1.5)
                    self.crawler.driver.execute_script("arguments[0].click();", category_button)
                    print("âœ… ì§ì¢…ì„ íƒ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!")
                    logger.info("Clicked category expansion button")
                    
                    # Wait for categories to expand
                    print("â³ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ í™•ìž¥ ëŒ€ê¸° ì¤‘...")
                    self.crawler.human_behavior.random_delay(2.0, 3.5)
                else:
                    print("âŒ ì§ì¢…ì„ íƒ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    logger.error("Category expansion button not found")
                    raise Exception("ì§ì¢…ì„ íƒ ë²„íŠ¼ ì°¾ê¸° ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ í™•ìž¥ ì‹¤íŒ¨: {e}")
                logger.error(f"Category section expansion failed: {e}")
                raise
            
            # 3. Select main job category (ì—°êµ¬ ë° ê³µí•™ê¸°ìˆ )
            print("ðŸ—ï¸ ì£¼ ì¹´í…Œê³ ë¦¬ ì„ íƒ ì¤‘: ì—°êµ¬ ë° ê³µí•™ê¸°ìˆ ")
            try:
                main_job_checkbox = self.crawler.wait_for_element(
                    self.site_config["selectors"]["filters"]["job_category_main"], timeout=8
                )
                if main_job_checkbox:
                    self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", main_job_checkbox)
                    self.crawler.human_behavior.random_delay(0.8, 1.5)
                    self.crawler.driver.execute_script("arguments[0].click();", main_job_checkbox)
                    print("âœ… ì£¼ ì¹´í…Œê³ ë¦¬ ì²´í¬ë°•ìŠ¤ ì„ íƒ ì™„ë£Œ!")
                    logger.info("Selected main job category checkbox")
                    
                    # Wait a moment before clicking the button
                    self.crawler.human_behavior.random_delay(0.8, 1.2)
                    
                    # 3.1. Click the main category button to expand sub-categories
                    print("ðŸ”˜ ì—°êµ¬ ë° ê³µí•™ê¸°ìˆ  ë²„íŠ¼ í´ë¦­í•˜ì—¬ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ í™•ìž¥ ì¤‘...")
                    main_category_button = self.crawler.wait_for_element(
                        self.site_config["selectors"]["filters"]["job_category_main_button"], timeout=8
                    )
                    if main_category_button:
                        self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", main_category_button)
                        self.crawler.human_behavior.random_delay(0.8, 1.5)
                        self.crawler.driver.execute_script("arguments[0].click();", main_category_button)
                        print("âœ… ì—°êµ¬ ë° ê³µí•™ê¸°ìˆ  ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!")
                        logger.info("Clicked main category button to expand sub-categories")
                        
                        # Wait for sub-categories to load
                        print("â³ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ë¡œë”© ëŒ€ê¸° ì¤‘...")
                        self.crawler.human_behavior.random_delay(3.0, 4.5)
                    else:
                        print("âŒ ì—°êµ¬ ë° ê³µí•™ê¸°ìˆ  ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        logger.error("Main category button not found")
                        raise Exception("ì£¼ ì¹´í…Œê³ ë¦¬ ë²„íŠ¼ ì°¾ê¸° ì‹¤íŒ¨")
                else:
                    print("âŒ ì£¼ ì¹´í…Œê³ ë¦¬ ì²´í¬ë°•ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    logger.error("Main job category checkbox not found")
                    raise Exception("ì£¼ ì¹´í…Œê³ ë¦¬ ì²´í¬ë°•ìŠ¤ ì°¾ê¸° ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ì£¼ ì¹´í…Œê³ ë¦¬ ì„ íƒ ì‹¤íŒ¨: {e}")
                logger.error(f"Main category selection failed: {e}")
                raise
            
            # 4. Select all relevant sub-categories
            print("ðŸ”§ ëª¨ë“  ê´€ë ¨ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì„ íƒ ì¤‘...")
            sub_categories = self.site_config["selectors"]["filters"]["sub_categories"]
            selected_count = 0
            
            for category_name, selector in sub_categories.items():
                try:
                    print(f"ðŸ“‹ {category_name} ì¹´í…Œê³ ë¦¬ ì„ íƒ ì‹œë„...")
                    category_checkbox = self.crawler.wait_for_element(selector, timeout=8)
                    if category_checkbox:
                        self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", category_checkbox)
                        self.crawler.human_behavior.random_delay(0.5, 1.0)
                        self.crawler.driver.execute_script("arguments[0].click();", category_checkbox)
                        selected_count += 1
                        print(f"âœ… {category_name} ì„ íƒ ì™„ë£Œ!")
                        logger.info(f"Selected sub-category: {category_name}")
                    else:
                        print(f"âš ï¸ {category_name} ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                        logger.warning(f"Sub-category not found: {category_name}")
                except Exception as e:
                    print(f"âš ï¸ {category_name} ì„ íƒ ì‹¤íŒ¨: {e}")
                    logger.debug(f"Sub-category selection failed for {category_name}: {e}")
                    continue
            
            print(f"ðŸ“Š ì´ {selected_count}ê°œ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì„ íƒ ì™„ë£Œ!")
            
            # 5. Click "ì§€ì—­ë³„" button to expand region selection
            print("ðŸ“ ì§€ì—­ë³„ ë²„íŠ¼ í´ë¦­í•˜ì—¬ ì§€ì—­ ì„ íƒ ì„¹ì…˜ í™•ìž¥ ì¤‘...")
            try:
                area_button = self.crawler.wait_for_element(
                    self.site_config["selectors"]["filters"]["area_button"], timeout=10
                )
                if area_button:
                    self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", area_button)
                    self.crawler.human_behavior.random_delay(0.8, 1.5)
                    self.crawler.driver.execute_script("arguments[0].click();", area_button)
                    print("âœ… ì§€ì—­ë³„ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!")
                    logger.info("Clicked area expansion button")
                    
                    # Wait for region list to appear
                    print("â³ ì§€ì—­ ëª©ë¡ í™•ìž¥ ëŒ€ê¸° ì¤‘...")
                    self.crawler.human_behavior.random_delay(2.5, 4.0)
                else:
                    print("âŒ ì§€ì—­ë³„ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    logger.error("Area expansion button not found")
                    raise Exception("ì§€ì—­ë³„ ë²„íŠ¼ ì°¾ê¸° ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ì§€ì—­ ì„¹ì…˜ í™•ìž¥ ì‹¤íŒ¨: {e}")
                logger.error(f"Area section expansion failed: {e}")
                raise
                
            # 6. Select Seoul region
            print("ðŸ™ï¸ ì„œìš¸ ì§€ì—­ ì„ íƒ ì¤‘...")
            try:
                seoul_button = self.crawler.wait_for_element(
                    self.site_config["selectors"]["filters"]["seoul_region"], timeout=10
                )
                if seoul_button:
                    self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", seoul_button)
                    self.crawler.human_behavior.random_delay(0.8, 1.5)
                    self.crawler.driver.execute_script("arguments[0].click();", seoul_button)
                    print("âœ… ì„œìš¸ ì§€ì—­ ì„ íƒ ì™„ë£Œ!")
                    logger.info("Selected Seoul region")
                    
                    # Wait for Seoul sub-region options to load
                    print("â³ ì„œìš¸ í•˜ìœ„ ì§€ì—­ ì˜µì…˜ ë¡œë”© ëŒ€ê¸° ì¤‘...")
                    self.crawler.human_behavior.random_delay(2.5, 3.5)
                else:
                    print("âŒ ì„œìš¸ ì§€ì—­ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    logger.error("Seoul region button not found")
                    raise Exception("ì„œìš¸ ì§€ì—­ ì„ íƒ ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ì„œìš¸ ì§€ì—­ ì„ íƒ ì‹¤íŒ¨: {e}")
                logger.error(f"Seoul region selection failed: {e}")
                raise
            
            # 7. Select whole Seoul area
            print("ðŸŒ ì„œìš¸ ì „ì²´ ì§€ì—­ ì„ íƒ ì¤‘...")
            try:
                seoul_whole = self.crawler.wait_for_element(
                    self.site_config["selectors"]["filters"]["seoul_whole"], timeout=8
                )
                if seoul_whole:
                    self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", seoul_whole)
                    self.crawler.human_behavior.random_delay(0.5, 1.0)
                    self.crawler.driver.execute_script("arguments[0].click();", seoul_whole)
                    print("âœ… ì„œìš¸ ì „ì²´ ì§€ì—­ ì„ íƒ ì™„ë£Œ!")
                    logger.info("Selected whole Seoul region")
                    
                    # Wait for selection to be processed
                    self.crawler.human_behavior.random_delay(1.5, 2.5)
                else:
                    print("âš ï¸ ì„œìš¸ ì „ì²´ ì„ íƒ ì˜µì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    logger.warning("Seoul whole region checkbox not found")
            except Exception as e:
                print(f"âš ï¸ ì„œìš¸ ì „ì²´ ì§€ì—­ ì„ íƒ ì‹¤íŒ¨: {e}")
                logger.debug(f"Seoul whole region selection failed: {e}")
            
            # 8. Submit search
            print("ðŸš€ í†µí•© ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
            try:
                search_start = time.time()
                search_button = self.crawler.wait_for_element(
                    self.site_config["selectors"]["filters"]["search_button"], timeout=12
                )
                if search_button:
                    self.crawler.driver.execute_script("arguments[0].scrollIntoView(true);", search_button)
                    self.crawler.human_behavior.random_delay(1.0, 2.0)
                    self.crawler.driver.execute_script("arguments[0].click();", search_button)
                    print("âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!")
                    logger.info(f"Clicked search button in {time.time() - search_start:.2f}s")
                    
                    # Wait for search results to load
                    print("â³ ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸° ì¤‘ (6ì´ˆ)...")
                    self.crawler.human_behavior.random_delay(6.0, 8.0)
                    print("âœ… ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ì™„ë£Œ!")
                else:
                    print("âŒ ê²€ìƒ‰ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                    logger.error("Search button not found")
                    raise Exception("ê²€ìƒ‰ ë²„íŠ¼ ì°¾ê¸° ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                logger.error(f"Search execution failed: {e}")
                raise
            
            print("ðŸŽ‰ Work24 í†µí•© í•„í„° ì ìš© ì™„ë£Œ!")
            print(f"ðŸ“‹ ì ìš©ëœ í•„í„°: ì—°êµ¬ ë° ê³µí•™ê¸°ìˆ  > {selected_count}ê°œ ì„œë¸Œì¹´í…Œê³ ë¦¬ > ì„œìš¸ ì „ì²´")
            if filters.keywords:
                print(f"ðŸ”¤ ì¶”ê°€ í‚¤ì›Œë“œ: '{filters.keywords}'")
            logger.info(f"Work24 comprehensive filters applied successfully in {time.time() - start_time:.2f}s")
            
        except Exception as e:
            print(f"âŒ Work24 í†µí•© í•„í„° ì ìš© ì‹¤íŒ¨: {e}")
            logger.error(f"Failed to apply Work24 comprehensive filters: {e}")
            raise
    
    def _apply_keyword_filter(self, keywords: str) -> None:
        """Apply keyword search filter."""
        keyword_selectors = [
            "#keywords",
            "[data-testid='keywords-input']",
            ".jobs-search-box__text-input",
            "input[placeholder*='keyword']",
            "input[placeholder*='title']"
        ]
        
        keyword_input = None
        for selector in keyword_selectors:
            keyword_input = self.crawler.safe_find_element(selector)
            if keyword_input:
                break
        
        if keyword_input:
            logger.debug(f"Applying keyword filter: {keywords}")
            self.crawler.human_behavior.human_click(keyword_input)
            self.crawler.human_behavior.human_type(keyword_input, keywords)
            self.crawler.human_behavior.random_delay(0.5, 1.0)
    
    def _apply_location_filter(self, location: str) -> None:
        """Apply location search filter."""
        location_selectors = [
            "#where",
            "[data-testid='location-input']",
            ".jobs-search-box__text-input[placeholder*='location']",
            "input[placeholder*='location']",
            "input[placeholder*='city']"
        ]
        
        location_input = None
        for selector in location_selectors:
            location_input = self.crawler.safe_find_element(selector)
            if location_input:
                break
        
        if location_input:
            logger.debug(f"Applying location filter: {location}")
            self.crawler.human_behavior.human_click(location_input)
            self.crawler.human_behavior.human_type(location_input, location)
            self.crawler.human_behavior.random_delay(0.5, 1.0)
    
    def _apply_job_type_filter(self, job_type: JobType) -> None:
        """Apply job type filter."""
        if self.crawler.site_name == "linkedin":
            self._apply_linkedin_job_type(job_type)
        elif self.crawler.site_name == "indeed":
            self._apply_indeed_job_type(job_type)
    
    def _apply_linkedin_job_type(self, job_type: JobType) -> None:
        """Apply LinkedIn job type filter."""
        job_type_mapping = {
            JobType.FULL_TIME: "F",
            JobType.PART_TIME: "P",
            JobType.CONTRACT: "C",
            JobType.TEMPORARY: "T",
            JobType.INTERNSHIP: "I"
        }
        
        if job_type in job_type_mapping:
            filter_button = self.crawler.safe_find_element(
                f"input[value='{job_type_mapping[job_type]}']"
            )
            if filter_button:
                self.crawler.human_behavior.human_click(filter_button)
    
    def _apply_indeed_job_type(self, job_type: JobType) -> None:
        """Apply Indeed job type filter."""
        job_type_dropdown = self.crawler.safe_find_element("#job-type-dropdown")
        if job_type_dropdown:
            self.crawler.human_behavior.human_click(job_type_dropdown)
            self.crawler.human_behavior.random_delay(0.5, 1.0)
            
            # Find the appropriate option
            job_type_text = job_type.value.replace("_", " ").title()
            option = self.crawler.safe_find_element(
                f"option[value*='{job_type.value}'], option:contains('{job_type_text}')"
            )
            if option:
                self.crawler.human_behavior.human_click(option)
    
    def _apply_experience_filter(self, experience: ExperienceLevel) -> None:
        """Apply experience level filter."""
        # Implementation varies by site
        if self.crawler.site_name == "linkedin":
            exp_mapping = {
                ExperienceLevel.ENTRY_LEVEL: "1",
                ExperienceLevel.MID_LEVEL: "3",
                ExperienceLevel.SENIOR_LEVEL: "4",
                ExperienceLevel.EXECUTIVE: "5",
                ExperienceLevel.INTERNSHIP: "2"
            }
            
            if experience in exp_mapping:
                exp_filter = self.crawler.safe_find_element(
                    f"input[value='{exp_mapping[experience]}']"
                )
                if exp_filter:
                    self.crawler.human_behavior.human_click(exp_filter)
    
    def _apply_date_filter(self, date_posted: str) -> None:
        """Apply date posted filter."""
        date_selectors = [
            "#date-posted-dropdown",
            ".jobs-search-dropdown[data-control-name='date_posted']"
        ]
        
        for selector in date_selectors:
            date_dropdown = self.crawler.safe_find_element(selector)
            if date_dropdown:
                self.crawler.human_behavior.human_click(date_dropdown)
                self.crawler.human_behavior.random_delay(0.5, 1.0)
                
                # Map date options
                date_option = self.crawler.safe_find_element(
                    f"option[value*='{date_posted}']"
                )
                if date_option:
                    self.crawler.human_behavior.human_click(date_option)
                break
    
    def _apply_remote_filter(self) -> None:
        """Apply remote work filter."""
        remote_selectors = [
            "input[value='remote']",
            "label:contains('Remote')",
            ".filter-pill:contains('Remote')"
        ]
        
        for selector in remote_selectors:
            remote_filter = self.crawler.safe_find_element(selector)
            if remote_filter:
                self.crawler.human_behavior.human_click(remote_filter)
                break
    
    def _submit_search(self) -> None:
        """Submit the search form."""
        search_button_selectors = [
            "button[type='submit']",
            ".jobs-search-form__submit-button",
            "#searchform button",
            ".search-button",
            "[data-testid='search-button']"
        ]
        
        for selector in search_button_selectors:
            search_button = self.crawler.wait_for_clickable(selector)
            if search_button:
                logger.debug("Submitting search")
                self.crawler.human_behavior.human_click(search_button)
                
                # Wait for search results to load
                self.crawler.human_behavior.random_delay(3.0, 6.0)
                return
        
        # If no search button found, try pressing Enter on keyword field
        keyword_input = self.crawler.safe_find_element("#keywords, input[placeholder*='keyword']")
        if keyword_input:
            keyword_input.send_keys("\n")
            self.crawler.human_behavior.random_delay(3.0, 6.0)
    
    def has_next_page(self) -> bool:
        """Check if there's a next page of results."""
        if self.crawler.site_name == "work24":
            return self._has_next_page_work24()
        else:
            # Standard logic for other sites
            next_button = self.crawler.safe_find_element(
                self.site_config["selectors"]["next_page"]
            )
            return next_button is not None and next_button.is_enabled()
    
    def _has_next_page_work24(self) -> bool:
        """Check if Work24 has next page by looking at pagination buttons."""
        try:
            print("ðŸ” ë‹¤ìŒ íŽ˜ì´ì§€ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸ ì¤‘...")
            
            # First, check if pagination container exists
            pagination_container = self.crawler.safe_find_element(
                self.site_config["selectors"]["pagination_container"]
            )
            
            if not pagination_container:
                print("âŒ íŽ˜ì´ì§€ë„¤ì´ì…˜ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # Get current page number
            current_page_element = self.crawler.safe_find_element(
                self.site_config["selectors"]["pagination_current"]
            )
            
            if not current_page_element:
                print("âš ï¸ í˜„ìž¬ íŽ˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                # Try alternative method - check if next button exists
                next_button = self.crawler.safe_find_element(
                    self.site_config["selectors"]["next_page"]
                )
                has_next = next_button is not None and next_button.is_enabled()
                print(f"ðŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ë‹¤ìŒ íŽ˜ì´ì§€ ì¡´ìž¬ ì—¬ë¶€: {has_next}")
                return has_next
            
            current_page = int(current_page_element.text.strip())
            next_page = current_page + 1
            
            print(f"ðŸ“„ í˜„ìž¬ íŽ˜ì´ì§€: {current_page}, í™•ì¸í•  ë‹¤ìŒ íŽ˜ì´ì§€: {next_page}")
            
            # Method 1: Check if specific next page button exists (most reliable)
            next_page_button = self.crawler.safe_find_element(
                f"button[onclick*='fn_Move({next_page})']"
            )
            
            if next_page_button and next_page_button.is_enabled():
                print(f"âœ… íŽ˜ì´ì§€ {next_page} ë²„íŠ¼ ë°œê²¬! ë‹¤ìŒ íŽ˜ì´ì§€ë¡œ ì´ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                return True
            
            # Method 2: Check the general next button
            next_button = self.crawler.safe_find_element(
                self.site_config["selectors"]["next_page"]
            )
            
            if next_button and next_button.is_enabled():
                print(f"âœ… ì¼ë°˜ ë‹¤ìŒ ë²„íŠ¼ ë°œê²¬! ë‹¤ìŒ íŽ˜ì´ì§€ë¡œ ì´ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                return True
            
            # Method 3: Look for any numbered page buttons higher than current
            all_page_buttons = self.crawler.safe_find_elements(
                "button[onclick*='fn_Move']"
            )
            
            max_available_page = current_page
            for button in all_page_buttons:
                onclick_attr = button.get_attribute("onclick")
                if onclick_attr:
                    # Extract page number from fn_Move(X)
                    page_match = re.search(r'fn_Move\((\d+)\)', onclick_attr)
                    if page_match:
                        page_num = int(page_match.group(1))
                        max_available_page = max(max_available_page, page_num)
            
            has_more_pages = max_available_page > current_page
            print(f"ðŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ìµœëŒ€ íŽ˜ì´ì§€: {max_available_page}, ë‹¤ìŒ íŽ˜ì´ì§€ ì¡´ìž¬: {has_more_pages}")
            
            return has_more_pages
            
        except Exception as e:
            print(f"âš ï¸ ë‹¤ìŒ íŽ˜ì´ì§€ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            logger.warning(f"Error checking next page: {e}")
            return False
    
    def go_to_next_page(self) -> bool:
        """Navigate to the next page of results."""
        try:
            if self.crawler.site_name == "work24":
                return self._go_to_next_page_work24()
            else:
                return self._go_to_next_page_standard()
                
        except Exception as e:
            logger.warning(f"Failed to navigate to next page: {e}")
            return False
    
    def _go_to_next_page_work24(self) -> bool:
        """Navigate to next page for Work24 using fn_Move() function."""
        try:
            # Get current page number
            current_page_element = self.crawler.safe_find_element(
                self.site_config["selectors"]["pagination_current"]
            )
            
            if not current_page_element:
                logger.warning("Could not find current page indicator")
                return False
            
            current_page = int(current_page_element.text.strip())
            next_page = current_page + 1
            
            print(f"ðŸ“„ íŽ˜ì´ì§€ {current_page} â†’ {next_page} ì´ë™ ì¤‘...")
            
            # Look for the specific next page button
            next_page_button = self.crawler.safe_find_element(
                f"button[onclick*='fn_Move({next_page})']"
            )
            
            if next_page_button:
                # Use JavaScript to execute fn_Move directly for faster navigation
                print(f"ðŸš€ JavaScriptë¡œ íŽ˜ì´ì§€ {next_page} ì´ë™...")
                self.crawler.driver.execute_script(f"fn_Move({next_page}); return false;")
                
                # Shorter wait for page load (optimized for speed)
                self.crawler.human_behavior.random_delay(2.0, 3.0)
                
                # Verify page change by checking current page indicator
                new_page_element = self.crawler.safe_find_element(
                    self.site_config["selectors"]["pagination_current"]
                )
                
                if new_page_element and int(new_page_element.text.strip()) == next_page:
                    print(f"âœ… íŽ˜ì´ì§€ {next_page} ì´ë™ ì™„ë£Œ!")
                    logger.info(f"Successfully navigated to page {next_page}")
                    return True
                else:
                    print(f"âš ï¸ íŽ˜ì´ì§€ ì´ë™ í™•ì¸ ì‹¤íŒ¨")
                    return False
            else:
                # Check if we can use the general next button
                next_button = self.crawler.safe_find_element(
                    self.site_config["selectors"]["next_page"]
                )
                
                if next_button and next_button.is_enabled():
                    print(f"ðŸ”„ ì¼ë°˜ ë‹¤ìŒ ë²„íŠ¼ìœ¼ë¡œ íŽ˜ì´ì§€ ì´ë™...")
                    next_button.click()
                    self.crawler.human_behavior.random_delay(2.0, 3.0)
                    return True
                    
                print(f"âŒ ë‹¤ìŒ íŽ˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.warning(f"Work24 pagination failed: {e}")
            return False
    
    def _go_to_next_page_standard(self) -> bool:
        """Standard pagination for LinkedIn/Indeed."""
        try:
            next_button = self.crawler.wait_for_clickable(
                self.site_config["selectors"]["next_page"]
            )
            
            if next_button:
                logger.debug("Navigating to next page")
                
                # Scroll to see the next button
                self.crawler.driver.execute_script(
                    "arguments[0].scrollIntoView({block: 'center'});", next_button
                )
                self.crawler.human_behavior.random_delay(1.0, 2.0)
                
                # Click next page
                self.crawler.human_behavior.human_click(next_button)
                
                # Wait for page to load
                self.crawler.human_behavior.random_delay(3.0, 6.0)
                
                return True
            
            return False
            
        except Exception as e:
            logger.warning(f"Standard pagination failed: {e}")
            return False